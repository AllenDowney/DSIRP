{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wanted-ocean",
   "metadata": {},
   "source": [
    "# Chapter xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-sessions",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "*Data Structures and Information Retrieval in Python*\n",
    "\n",
    "Copyright 2021 Allen Downey\n",
    "\n",
    "License: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cloudy-flooring",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print('Downloaded ' + local)\n",
    "    \n",
    "# download('https://github.com/AllenDowney/DSIRP/raw/main/utils.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-portugal",
   "metadata": {},
   "source": [
    "[Click here to run this chapter on Colab](https://colab.research.google.com/github/AllenDowney/DSIRP/blob/main/chapters/chap01.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-count",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sonic-appointment",
   "metadata": {},
   "source": [
    "# Sorting\n",
    "\n",
    "Computer science departments have an unhealthy obsession with sort\n",
    "algorithms. Based on the amount of time CS students spend on the topic,\n",
    "you would think that choosing sort algorithms is the cornerstone of\n",
    "modern software engineering. Of course, the reality is that software\n",
    "developers can go years, or entire careers, without thinking about how\n",
    "sorting works. For almost all applications, they use whatever\n",
    "general-purpose algorithm is provided by the language or libraries they\n",
    "use. And usually that's just fine.\n",
    "\n",
    "So if you skip this chapter and learn nothing about sort algorithms, you\n",
    "can still be an excellent developer. But there are a few reasons you\n",
    "might want to do it anyway:\n",
    "\n",
    "1.  Although there are general-purpose algorithms that work well for the\n",
    "    vast majority of applications, there are two special-purpose\n",
    "    algorithms you might need to know about: radix sort and bounded heap\n",
    "    sort.\n",
    "\n",
    "2.  One sort algorithm, merge sort, makes an excellent teaching example\n",
    "    because it demonstrates an important and useful strategy for\n",
    "    algorithm design, called \"divide-conquer-glue\". Also, when we\n",
    "    analyze its performance, you will learn about an order of growth we\n",
    "    have not seen before, **linearithmic**. Finally, some of the most\n",
    "    widely-used algorithms are hybrids that include elements of merge\n",
    "    sort.\n",
    "\n",
    "3.  One other reason to learn about sort algorithms is that technical\n",
    "    interviewers love to ask about them. If you want to get hired, it\n",
    "    helps if you can demonstrate CS cultural literacy.\n",
    "\n",
    "So, in this chapter we'll analyze insertion sort, you will implement\n",
    "merge sort, I'll tell you about radix sort, and you will write a simple\n",
    "version of a bounded heap sort.\n",
    "\n",
    "## Insertion sort\n",
    "\n",
    "We'll start with insertion sort, mostly because it is simple to describe\n",
    "and implement. It is not very efficient, but it has some redeeming\n",
    "qualities, as we'll see.\n",
    "\n",
    "Rather than explain the algorithm here, I suggest you read the insertion\n",
    "sort Wikipedia page at <http://thinkdast.com/insertsort>, which includes\n",
    "pseudocode and animated examples. Come back when you get the general\n",
    "idea.\n",
    "\n",
    "Here's an implementation of insertion sort in Java:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "public class ListSorter<T> {\n",
    "\n",
    "    public void insertionSort(List<T> list, Comparator<T> comparator) {\n",
    "\n",
    "        for (int i=1; i < list.size(); i++) {\n",
    "            T elt_i = list.get(i);\n",
    "            int j = i;\n",
    "            while (j > 0) {\n",
    "                T elt_j = list.get(j-1);\n",
    "                if (comparator.compare(elt_i, elt_j) >= 0) {\n",
    "                    break;\n",
    "                }\n",
    "                list.set(j, elt_j);\n",
    "                j--;\n",
    "            }\n",
    "            list.set(j, elt_i);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-baking",
   "metadata": {},
   "source": [
    "I define a class, `ListSorter`, as a container for sort algorithms. By\n",
    "using the type parameter, `T`, we can write methods that work on lists\n",
    "containing any object type.\n",
    "\n",
    "`insertionSort` takes two parameters, a `List` of any kind and a\n",
    "`Comparator` that knows how to compare type `T` objects. It sorts the\n",
    "list \"in place\", which means it modifies the existing list and does not\n",
    "have to allocate any new space.\n",
    "\n",
    "The following example shows how to call this method with a `List` of\n",
    "`Integer` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "List<Integer> list = new ArrayList<Integer>(\n",
    "    Arrays.asList(3, 5, 1, 4, 2));\n",
    "\n",
    "Comparator<Integer> comparator = new Comparator<Integer>() {\n",
    "    @Override\n",
    "    public int compare(Integer elt1, Integer elt2) {\n",
    "        return elt1.compareTo(elt2);\n",
    "    }\n",
    "};\n",
    "\n",
    "ListSorter<Integer> sorter = new ListSorter<Integer>();\n",
    "sorter.insertionSort(list, comparator);\n",
    "System.out.println(list);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-theology",
   "metadata": {},
   "source": [
    "`insertionSort` has two nested loops, so you might guess that its\n",
    "runtime is quadratic. In this case, that turns out to be correct, but\n",
    "before you jump to that conclusion, you have to check that the number of\n",
    "times each loop runs is proportional to $n$, the size of the array.\n",
    "\n",
    "The outer loop iterates from 1 to `list.size()`, so it is linear in the\n",
    "size of the list, $n$. The inner loop iterates from `i` to 0, so it is\n",
    "also linear in $n$. Therefore, the total number of times the inner loop\n",
    "runs is quadratic.\n",
    "\n",
    "If you are not sure about that, here's the argument:\n",
    "\n",
    "-   The first time through, $i=1$ and the inner loop runs at most once.\n",
    "\n",
    "-   The second time, $i=2$ and the inner loop runs at most twice.\n",
    "\n",
    "-   The last time, $i=n-1$ and the inner loop runs at most $n-1$ times.\n",
    "\n",
    "So the total number of times the inner loop runs is the sum of the\n",
    "series $1, 2, \\ldots , n-1$, which is $n (n-1) / 2$. And the leading\n",
    "term of that expression (the one with the highest exponent) is $n^2$.\n",
    "\n",
    "In the worst case, insertion sort is quadratic. However:\n",
    "\n",
    "1.  If the elements are already sorted, or nearly so, insertion sort is\n",
    "    linear. Specifically, if each element is no more than $k$ locations\n",
    "    away from where it should be, the inner loop never runs more than\n",
    "    $k$ times, and the total runtime is $O(kn)$.\n",
    "\n",
    "2.  Because the implementation is simple, the overhead is low; that is,\n",
    "    although the runtime is $a n^2$, the coefficient of the leading\n",
    "    term, $a$, is probably small.\n",
    "\n",
    "So if we know that the array is nearly sorted, or is not very big,\n",
    "insertion sort might be a good choice. But for large arrays, we can do\n",
    "better. In fact, much better.\n",
    "\n",
    "## Exercise 14\n",
    "\n",
    "Merge sort is one of several algorithms whose runtime is better than\n",
    "quadratic. Again, rather than explaining the algorithm here, I suggest\n",
    "you read about it on Wikipedia at <http://thinkdast.com/mergesort>. Once\n",
    "you get the idea, come back and you can test your understanding by\n",
    "writing an implementation.\n",
    "\n",
    "In the repository for this book, you'll find the source files for this\n",
    "exercise:\n",
    "\n",
    "-   `ListSorter.java`\n",
    "\n",
    "-   `ListSorterTest.java`\n",
    "\n",
    "Run `ant build` to compile the source files, then run\n",
    "`ant ListSorterTest`. As usual, it should fail, because you have work to\n",
    "do.\n",
    "\n",
    "In `ListSorter.java`, I've provided an outline of two methods,\n",
    "`mergeSortInPlace` and `mergeSort`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "public void mergeSortInPlace(List<T> list, Comparator<T> comparator) {\n",
    "    List<T> sorted = mergeSortHelper(list, comparator);\n",
    "    list.clear();\n",
    "    list.addAll(sorted);\n",
    "}\n",
    "\n",
    "private List<T> mergeSort(List<T> list, Comparator<T> comparator) {\n",
    "   // TODO: fill this in!\n",
    "   return null;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-saying",
   "metadata": {},
   "source": [
    "These two methods do the same thing but provide different interfaces.\n",
    "`mergeSort` takes a list and returns a new list with the same elements\n",
    "sorted in ascending order. `mergeSortInPlace` is a `void` method that\n",
    "modifies an existing list.\n",
    "\n",
    "Your job is to fill in `mergeSort`. Before you write a fully recursive\n",
    "version of merge sort, start with something like this:\n",
    "\n",
    "1.  Split the list in half.\n",
    "\n",
    "2.  Sort the halves using `Collections.sort` or `insertionSort`.\n",
    "\n",
    "3.  Merge the sorted halves into a complete sorted list.\n",
    "\n",
    "This will give you a chance to debug the merge code without dealing with\n",
    "the complexity of a recursive method.\n",
    "\n",
    "Next, add a base case (see <http://thinkdast.com/basecase>). If you are\n",
    "given a list with only one element, you could return it immediately,\n",
    "since it is already sorted, sort of. Or if the length of the list is\n",
    "below some threshold, you could sort it using `Collections.sort` or\n",
    "`insertionSort`. Test the base case before you proceed.\n",
    "\n",
    "Finally, modify your solution so it makes two recursive calls to sort\n",
    "the halves of the array. When you get it working, `testMergeSort` and\n",
    "`testMergeSortInPlace` should pass.\n",
    "\n",
    "## Analysis of merge sort\n",
    "\n",
    "To classify the runtime of merge sort, it helps to think in terms of\n",
    "levels of recursion and how much work is done on each level. Suppose we\n",
    "start with a list that contains $n$ elements. Here are the steps of the\n",
    "algorithm:\n",
    "\n",
    "1.  Make two new arrays and copy half of the elements into each.\n",
    "\n",
    "2.  Sort the two halves.\n",
    "\n",
    "3.  Merge the halves.\n",
    "\n",
    "Figure [\\[fig-sort1\\]](#fig-sort1){reference-type=\"ref\"\n",
    "reference=\"fig-sort1\"} shows these steps.\n",
    "\n",
    "![Representation of merge sort showing one level of\n",
    "recursion.](figs/merge_sort1.pdf){height=\"2.5in\"}\n",
    "\n",
    "The first step copies each of the elements once, so it is linear. The\n",
    "third step also copies each element once, so it is also linear. Now we\n",
    "need to figure out the complexity of step 2. To do that, it helps to\n",
    "looks at a different picture of the computation, which shows the levels\n",
    "of recursion, as in\n",
    "Figure [\\[fig-sort2\\]](#fig-sort2){reference-type=\"ref\"\n",
    "reference=\"fig-sort2\"}.\n",
    "\n",
    "![Representation of merge sort showing all levels of\n",
    "recursion.](figs/merge_sort2.pdf){height=\"2in\"}\n",
    "\n",
    "At the top level, we have $1$ list with $n$ elements. For simplicity,\n",
    "let's assume $n$ is a power of 2. At the next level there are $2$ lists\n",
    "with $n/2$ elements. Then $4$ lists with $n/4$ elements, and so on until\n",
    "we get to $n$ lists with $1$ element.\n",
    "\n",
    "On every level we have a total of $n$ elements. On the way down, we have\n",
    "to split the arrays in half, which takes time proportional to $n$ on\n",
    "every level. On the way back up, we have to merge a total of $n$\n",
    "elements, which is also linear.\n",
    "\n",
    "If the number of levels is $h$, the total amount of work for the\n",
    "algorithm is $O(nh)$. So how many levels are there? There are two ways\n",
    "to think about that:\n",
    "\n",
    "1.  How many times do we have to cut $n$ in half to get to 1?\n",
    "\n",
    "2.  Or, how many times do we have to double $1$ before we get to $n$?\n",
    "\n",
    "Another way to ask the second question is \"What power of 2 is $n$?\"\n",
    "\n",
    "$2^h = n$\n",
    "\n",
    "Taking the $\\log_2$ of both sides yields\n",
    "\n",
    "$h = \\log_2 n$\n",
    "\n",
    "So the total time is $O(n \\log n)$. I didn't bother to write the base of\n",
    "the logarithm because logarithms with different bases differ by a\n",
    "constant factor, so all logarithms are in the same order of growth.\n",
    "\n",
    "Algorithms in $O(n \\log n)$ are sometimes called \"linearithmic\", but\n",
    "most people just say \"n log n\".\n",
    "\n",
    "It turns out that $O(n \\log n)$ is the theoretical lower bound for sort\n",
    "algorithms that work by comparing elements to each other. That means\n",
    "there is no \"comparison sort\" whose order of growth is better than\n",
    "$n \\log n$. See <http://thinkdast.com/compsort>.\n",
    "\n",
    "But as we'll see in the next section, there are non-comparison sorts\n",
    "that take linear time!\n",
    "\n",
    "## Radix sort\n",
    "\n",
    "During the 2008 United States Presidential Campaign, candidate Barack\n",
    "Obama was asked to perform an impromptu algorithm analysis when he\n",
    "visited Google. Chief executive Eric Schmidt jokingly asked him for \"the\n",
    "most efficient way to sort a million 32-bit integers.\" Obama had\n",
    "apparently been tipped off, because he quickly replied, \"I think the\n",
    "bubble sort would be the wrong way to go.\" You can watch the video at\n",
    "<http://thinkdast.com/obama>.\n",
    "\n",
    "Obama was right: bubble sort is conceptually simple but its runtime is\n",
    "quadratic; and even among quadratic sort algorithms, its performance is\n",
    "not very good. See <http://thinkdast.com/bubble>.\n",
    "\n",
    "The answer Schmidt was probably looking for is \"radix sort\", which is a\n",
    "**non-comparison** sort algorithm that works if the size of the elements\n",
    "is bounded, like a 32-bit integer or a 20-character string.\n",
    "\n",
    "To see how this works, imagine you have a stack of index cards where\n",
    "each card contains a three-letter word. Here's how you could sort the\n",
    "cards:\n",
    "\n",
    "1.  Make one pass through the cards and divide them into buckets based\n",
    "    on the first letter. So words starting with `a` should be in one\n",
    "    bucket, followed by words starting with `b`, and so on.\n",
    "\n",
    "2.  Divide each bucket again based on the second letter. So words\n",
    "    starting with `aa` should be together, followed by words starting\n",
    "    with `ab`, and so on. Of course, not all buckets will be full, but\n",
    "    that's OK.\n",
    "\n",
    "3.  Divide each bucket again based on the third letter.\n",
    "\n",
    "At this point each bucket contains one element, and the buckets are\n",
    "sorted in ascending order.\n",
    "Figure [\\[fig-sort3\\]](#fig-sort3){reference-type=\"ref\"\n",
    "reference=\"fig-sort3\"} shows an example with three-letter words.\n",
    "\n",
    "![Example of radix sort with three-letter\n",
    "words.](figs/radix_sort1.pdf){height=\"2.0in\"}\n",
    "\n",
    "The top row shows the unsorted words. The second row shows what the\n",
    "buckets look like after the first pass. The words in each bucket begin\n",
    "with the same letter.\n",
    "\n",
    "After the second pass, the words in each bucket begin with the same two\n",
    "letters. After the third pass, there can be only one word in each\n",
    "bucket, and the buckets are in order.\n",
    "\n",
    "During each pass, we iterate through the elements and add them to\n",
    "buckets. As long as the buckets allow addition in constant time, each\n",
    "pass is linear.\n",
    "\n",
    "The number of passes, which I'll call $w$, depends on the \"width\" of the\n",
    "words, but it doesn't depend on the number of words, $n$. So the order\n",
    "of growth is $O(wn)$, which is linear in $n$.\n",
    "\n",
    "There are many variations on radix sort, and many ways to implement each\n",
    "one. You can read more about them at <http://thinkdast.com/radix>. As an\n",
    "optional exercise, consider writing a version of radix sort.\n",
    "\n",
    "## Heap sort\n",
    "\n",
    "In addition to radix sort, which applies when the things you want to\n",
    "sort are bounded in size, there is one other special-purpose sorting\n",
    "algorithm you might encounter: bounded heap sort. Bounded heap sort is\n",
    "useful if you are working with a very large dataset and you want to\n",
    "report the \"Top 10\" or \"Top k\" for some value of $k$ much smaller than\n",
    "$n$.\n",
    "\n",
    "For example, suppose you are monitoring a Web service that handles a\n",
    "billion transactions per day. At the end of each day, you want to report\n",
    "the $k$ biggest transactions (or slowest, or any other superlative). One\n",
    "option is to store all transactions, sort them at the end of the day,\n",
    "and select the top $k$. That would take time proportional to $n \\log n$,\n",
    "and it would be very slow because we probably can't fit a billion\n",
    "transactions in the memory of a single program. We would have to use an\n",
    "\"out of core\" sort algorithm. You can read about external sorting at\n",
    "<http://thinkdast.com/extsort>.\n",
    "\n",
    "Using a bounded heap, we can do much better! Here's how we will proceed:\n",
    "\n",
    "1.  I'll explain (unbounded) heap sort.\n",
    "\n",
    "2.  You'll implement it.\n",
    "\n",
    "3.  I'll explain bounded heap sort and analyze it.\n",
    "\n",
    "To understand heap sort, you have to understand a heap, which is a data\n",
    "structure similar to a binary search tree (BST). Here are the\n",
    "differences:\n",
    "\n",
    "-   In a BST, every node, `x`, has the \"BST property\": all nodes in the\n",
    "    left subtree of `x` are less than `x` and all nodes in the right\n",
    "    subtree are greater than `x`.\n",
    "\n",
    "-   In a heap, every node, `x`, has the \"heap property\": all nodes in\n",
    "    both subtrees of `x` are greater than `x`.\n",
    "\n",
    "-   Heaps are like balanced BSTs; when you add or remove elements, they\n",
    "    do some extra work to rebalance the tree. As a result, they can be\n",
    "    implemented efficiently using an array of elements.\n",
    "\n",
    "The smallest element in a heap is always at the root, so we can find it\n",
    "in constant time. Adding and removing elements from a heap takes time\n",
    "proportional to the height of the tree $h$. And because the heap is\n",
    "always balanced, $h$ is proportional to $\\log n$. You can read more\n",
    "about heaps at <http://thinkdast.com/heap>.\n",
    "\n",
    "The Java `PriorityQueue` is implemented using a heap. `PriorityQueue`\n",
    "provides the methods specified in the `Queue` interface, including\n",
    "`offer` and `poll`:\n",
    "\n",
    "-   `offer`: Adds an element to the queue, updating the heap so that\n",
    "    every node has the \"heap property\". Takes $\\log n$ time.\n",
    "\n",
    "-   `poll`: Removes the smallest element in the queue from the root and\n",
    "    updates the heap. Takes $\\log n$ time.\n",
    "\n",
    "Given a `PriorityQueue`, you can easily sort of a collection of $n$\n",
    "elements like this:\n",
    "\n",
    "1.  Add all elements of the collection to a `PriorityQueue` using\n",
    "    `offer`.\n",
    "\n",
    "2.  Remove the elements from the queue using `poll` and add them to a\n",
    "    `List`.\n",
    "\n",
    "Because `poll` returns the smallest element remaining in the queue, the\n",
    "elements are added to the `List` in ascending order. This way of sorting\n",
    "is called **heap sort** (see <http://thinkdast.com/heapsort>).\n",
    "\n",
    "Adding $n$ elements to the queue takes $n \\log n$ time. So does removing\n",
    "$n$ elements. So the runtime for heap sort is $O(n \\log n)$.\n",
    "\n",
    "In the repository for this book, in `ListSorter.java` you'll find the\n",
    "outline of a method called `heapSort`. Fill it in and then run\n",
    "`ant ListSorterTest` to confirm that it works.\n",
    "\n",
    "## Bounded heap\n",
    "\n",
    "A bounded heap is a heap that is limited to contain at most $k$\n",
    "elements. If you have $n$ elements, you can keep track of the $k$\n",
    "largest elements like this:\n",
    "\n",
    "Initially, the heap is empty. For each element, `x`:\n",
    "\n",
    "-   Branch 1: If the heap is not full, add `x` to the heap.\n",
    "\n",
    "-   Branch 2: If the heap is full, compare `x` to the *smallest* element\n",
    "    in the heap. If `x` is smaller, it cannot be one of the largest $k$\n",
    "    elements, so you can discard it.\n",
    "\n",
    "-   Branch 3: If the heap is full and `x` is greater than the smallest\n",
    "    element in the heap, remove the smallest element from the heap and\n",
    "    add `x`.\n",
    "\n",
    "Using a heap with the smallest element at the top, we can keep track of\n",
    "the largest $k$ elements. Let's analyze the performance of this\n",
    "algorithm. For each element, we perform one of:\n",
    "\n",
    "-   Branch 1: Adding an element to the heap is $O(\\log k)$.\n",
    "\n",
    "-   Branch 2: Finding the smallest element in the heap is $O(1)$.\n",
    "\n",
    "-   Branch 3: Removing the smallest element is $O(\\log k)$. Adding `x`\n",
    "    is also $O(\\log k)$.\n",
    "\n",
    "In the worst case, if the elements appear in ascending order, we always\n",
    "run Branch 3. In that case, the total time to process $n$ elements is\n",
    "$O(n \\log k)$, which is linear in $n$.\n",
    "\n",
    "In `ListSorter.java` you'll find the outline of a method called `topK`\n",
    "that takes a `List`, a `Comparator`, and an integer $k$. It should\n",
    "return the $k$ largest elements in the `List` in ascending order. Fill\n",
    "it in and then run to confirm that it works.\n",
    "\n",
    "## Space complexity\n",
    "\n",
    "Until now we have talked a lot about runtime analysis, but for many\n",
    "algorithms we are also concerned about space. For example, one of the\n",
    "drawbacks of merge sort is that it makes copies of the data. In our\n",
    "implementation, the total amount of space it allocates is $O(n \\log n)$.\n",
    "With a more clever implementation, you can get the space requirement\n",
    "down to $O(n)$.\n",
    "\n",
    "In contrast, insertion sort doesn't copy the data because it sorts the\n",
    "elements in place. It uses temporary variables to compare two elements\n",
    "at a time, and it uses a few other local variables. But its space use\n",
    "doesn't depend on $n$.\n",
    "\n",
    "Our implementation of heap sort creates a new `PriorityQueue` to store\n",
    "the elements, so the space is $O(n)$; but if you are allowed to sort the\n",
    "list in place, you can run heap sort with $O(1)$ space.\n",
    "\n",
    "One of the benefits of the bounded heap algorithm you just implemented\n",
    "is that it only needs space proportional to $k$ (the number of elements\n",
    "we want to keep), and $k$ is often much smaller than $n$.\n",
    "\n",
    "Software developers tend to pay more attention to runtime than space,\n",
    "and for many applications, that's appropriate. But for large datasets,\n",
    "space can be just as important or more so. For example:\n",
    "\n",
    "1.  If a dataset doesn't fit into the memory of one program, the run\n",
    "    time often increases dramatically, or it might not run at all. If\n",
    "    you choose an algorithm that needs less space, and that makes it\n",
    "    possible to fit the computation into memory, it might run much\n",
    "    faster. In the same vein, a program that uses less space might make\n",
    "    better use of CPU caches and run faster (see\n",
    "    <http://thinkdast.com/cache>).\n",
    "\n",
    "2.  On a server that runs many programs at the same time, if you can\n",
    "    reduce the space needed for each program, you might be able to run\n",
    "    more programs on the same server, which reduces hardware and energy\n",
    "    costs.\n",
    "\n",
    "So those are some reasons you should know at least a little bit about\n",
    "the space needs of algorithms."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
